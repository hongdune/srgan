{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.python.keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_base_block(x):\n",
    "    out = layers.Conv2D(64, 3, 1, \"same\")(x)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.PReLU(shared_axes=[1,2])(out)\n",
    "    out = layers.Conv2D(64, 3, 1, \"same\")(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    return layers.Add()([x, out])\n",
    "\n",
    "# 그림의 뒤쪽 연두색 블록을 정의합니다.\n",
    "def upsample_block(x):\n",
    "    out = layers.Conv2D(256, 3, 1, \"same\")(x)\n",
    "    # 그림의 PixelShuffler 라고 쓰여진 부분을 아래와 같이 구현합니다.\n",
    "    out = layers.Lambda(lambda x: tf.nn.depth_to_space(x, 2))(out)\n",
    "    return layers.PReLU(shared_axes=[1,2])(out)\n",
    "    \n",
    "# 전체 Generator를 정의합니다.\n",
    "def get_generator(input_shape=(None, None, 3)):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    out = layers.Conv2D(64, 9, 1, \"same\")(inputs)\n",
    "    out = residual = layers.PReLU(shared_axes=[1,2])(out)\n",
    "    \n",
    "    for _ in range(5):\n",
    "        out = gene_base_block(out)\n",
    "    \n",
    "    out = layers.Conv2D(64, 3, 1, \"same\")(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.Add()([residual, out])\n",
    "    \n",
    "    for _ in range(2):\n",
    "        out = upsample_block(out)\n",
    "        \n",
    "    out = layers.Conv2D(3, 9, 1, \"same\", activation=\"tanh\")(out)\n",
    "    return Model(inputs, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그림의 파란색 블록을 정의합니다.\n",
    "def disc_base_block(x, n_filters=128):\n",
    "    out = layers.Conv2D(n_filters, 3, 1, \"same\")(x)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.LeakyReLU()(out)\n",
    "    out = layers.Conv2D(n_filters, 3, 2, \"same\")(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    return layers.LeakyReLU()(out)\n",
    "\n",
    "# 전체 Discriminator 정의합니다.\n",
    "def get_discriminator(input_shape=(None, None, 3)):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    out = layers.Conv2D(64, 3, 1, \"same\")(inputs)\n",
    "    out = layers.LeakyReLU()(out)\n",
    "    out = layers.Conv2D(64, 3, 2, \"same\")(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.LeakyReLU()(out)\n",
    "    \n",
    "    for n_filters in [128, 256, 512]:\n",
    "        out = disc_base_block(out, n_filters)\n",
    "    \n",
    "    out = layers.Dense(1024)(out)\n",
    "    out = layers.LeakyReLU()(out)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(out)\n",
    "    return Model(inputs, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_extractor(input_shape=(None, None, 3)):\n",
    "    vgg = applications.vgg19.VGG19(\n",
    "        include_top=False, \n",
    "        weights=\"imagenet\", \n",
    "        input_shape=input_shape\n",
    "    )\n",
    "    # 아래 vgg.layers[20]은 vgg 내의 마지막 convolutional layer 입니다.\n",
    "    return Model(vgg.input, vgg.layers[20].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_img(model, image):\n",
    "    image = tf.cast(image[np.newaxis, ...], tf.float32)\n",
    "    sr = model.predict(image)\n",
    "    sr = tf.clip_by_value(sr, 0, 255)\n",
    "    sr = tf.round(sr)\n",
    "    sr = tf.cast(sr, tf.uint8)\n",
    "    return np.array(sr)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(target_img_path):\n",
    "    \n",
    "    model_file = 'srgan/models/srgan_G.h5'\n",
    "    model = tf.keras.models.load_model(model_file)\n",
    "    \n",
    "    img = pilimg.open(target_img_path)\n",
    "    npimg = make_img(model, img)\n",
    "    reformed_img = Image.fromarray(npimg)\n",
    "    \n",
    "    result_img_name = target_img_path.split('.')[0].split('/')[-1]\n",
    "    result_prefix = 'srgan/images/reformed_'+result_img_name\n",
    "    \n",
    "    \n",
    "    fname = result_prefix + '.png'\n",
    "    reformed_img.save(fname)\n",
    "    \n",
    "    \n",
    "    return fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
